# âš™ï¸ Predictive Maintenance Model Comparison  

## ğŸ“ Project Overview  
This project implements and compares multiple machine learning models for predictive maintenance using the **NASA C-MAPSS (Turbofan Engine Degradation Simulation)** dataset.  

The goal is to **predict engine failures before they occur**, enabling proactive maintenance and avoiding costly unplanned shutdowns.  

---

## ğŸ”¬ Model Comparison  

### 1ï¸âƒ£ LSTM Neural Network (Deep Learning)  
**Architecture**: Multi-layer LSTM with sequence processing  

**Key Specs**:  
- Input: 50 time steps  
- Architecture: LSTM(128) â†’ Dropout(0.3) â†’ LSTM(64) â†’ Dropout(0.3) â†’ LSTM(32) â†’ Dense(64) â†’ Dense(1)  
- Features: 17 after removing constant columns  
- Preprocessing: MinMax scaling + sequence generation  

**Performance**:  
- Accuracy: 88.85%  
- RMSE: 13.87  
- RÂ²: 0.89  
- MAE: 10.43  
- NASA Score: 280.01  

âœ… **Strengths**: Temporal patterns, high RÂ², strong predictive power  
âš ï¸ **Limitations**: Heavy preprocessing, computationally intensive  

---

### 2ï¸âƒ£ GRU Neural Network (Deep Learning)  
**Architecture**: Multi-layer GRU with sequence processing  

**Key Specs**: Similar to LSTM but with GRU cells (128 â†’ 64 â†’ 32)  

**Performance**:  
- Accuracy: 88.98%  
- RMSE: 13.80  
- RÂ²: 0.89  
- MAE: 10.33  
- NASA Score: 299.28  

âœ… **Strengths**: Similar to LSTM but faster training  
âš ï¸ **Limitations**: Still expensive, requires tuning  

---

### 3ï¸âƒ£ Random Forest Classifier  
**Approach**: Binary classification (failure â‰¤ 30 cycles = 1)  

**Performance**:  
- Accuracy: 96.93%  
- Precision (Failure): 0.95  
- Recall (Failure): 0.85  
- F1-Score (Failure): 0.90  

âœ… **Strengths**: Best precision/recall balance, interpretable  
âš ï¸ **Limitations**: Only binary output (no RUL prediction)  

---

### 4ï¸âƒ£ Gradient Boosting Classifier  
**Performance**:  
- Accuracy: 96.50%  
- Precision: 0.92  
- Recall: 0.85  
- F1-Score: 0.88  

âœ… **Strengths**: Good balance, error-correcting  
âš ï¸ **Limitations**: Prone to overfitting, binary only  

---

### 5ï¸âƒ£ Support Vector Machine (SVM)  
**Performance**:  
- Accuracy: 94.86%  
- Precision: 0.76  
- Recall: **0.97**  
- F1-Score: 0.86  

âœ… **Strengths**: Outstanding recall, minimal missed failures  
âš ï¸ **Limitations**: More false alarms, slower for big data  

---

## ğŸ“Š Model Performance Summary  

| Model            | Accuracy/RÂ² | Precision | Recall | F1-Score | Key Advantage |
|------------------|-------------|-----------|--------|----------|---------------|
| **LSTM**         | 88.85% / 0.89 | - | - | - | Temporal patterns, RUL prediction |
| **GRU**          | 88.98% / 0.89 | - | - | - | Faster training vs LSTM |
| **Random Forest** | 96.93% | 0.95 | 0.85 | 0.90 | Best balance |
| **Gradient Boosting** | 96.50% | 0.92 | 0.85 | 0.88 | Balanced performance |
| **SVM**          | 94.86% | 0.76 | **0.97** | 0.86 | Highest recall |

---

## ğŸ”‘ Insights & Trade-offs  

- **LSTM/GRU** â†’ RUL prediction, complex but detailed  
- **Random Forest** â†’ Best precision-recall balance, interpretable  
- **SVM** â†’ Highest recall, but more false alarms  

---

## âœ… Recommendations  

- **Primary** â†’ Random Forest (best overall)  
- **Secondary** â†’ SVM (safety-critical cases)  
- **Specialized** â†’ LSTM/GRU (detailed RUL planning)  

---

## ğŸ› ï¸ Feature Engineering Impact  

- Rolling mean/std (10-cycle windows)  
- Temporal trends  
- Removal of constant features  
- Class balancing  

---

## ğŸ Conclusion  

- **Random Forest** â†’ Best for general use  
- **SVM** â†’ Best for safety-critical  
- **LSTM/GRU** â†’ Best for RUL estimation  
- **Gradient Boosting** â†’ Solid alternative  

---

## ğŸš€ Future Improvements  

- **Deep Learning**: Try Transformers for sequential data  
- **Deployment**: Containerize with Docker, deploy to cloud  
- **Visualization**: Add live dashboards for sensor streams  
- **MLOps**: Add automated retraining and failure alerts  
